  <h2 align="center">JCP-Stack</h2>

  <p align="center">
    An efficient way to scrape results from the ACM, Springer and IEEE Xplore digital libraries
    <br />
    <a href="">View Demo **TO-DO**</a> <!-- TODO: add link to video demo on website (embedded youtube link) -->
  </p>
</p>

<!-- TABLE OF CONTENTS -->
<details open="open">
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
      <ul>
        <li><a href="#onomatology">Onomatology</a></li>
        <li><a href="#built-with">Built With</a></li>
      </ul>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#installation">Installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
  </ol>
</details>



<!-- ABOUT THE PROJECT -->
## About The Project

This project aims to help researchers find and sort papers from the ACM, Springer and IEEE Xplore online databases efficiently. I have compiled a list of over 250 journals and conferences with their CCF, Core and Qualis rankings in `Selected Journals and Conferences.csv`. This web scraper compares the [similarity (Levenshtein ratio)](https://rawgit.com/ztane/python-Levenshtein/master/docs/Levenshtein.html#Levenshtein-ratio) between every single search result's journal/conference title and those listed in `Selected Journals and Conferences.csv`. If the similarity between them is greater than or equal to a user-specified percentage, then the result is placed in a CSV file whose path and name is also selected by the user. Once the web scraper has completed traversing each page generated by the user's search term, analyzing the results therein, and storing the ones that fit the given criteria, it alerts the user of its status prior to restarting. 

### Onomatology

"JCP-Stack" is short for "Journal/Conference Paper Stack" given that executing this program (ideally) outputs a CSV file that contains information about a stack of journal/conference papers related to a given keyword. 


### Built With

* appdirs==1.4.4
* beautifulsoup4==4.9.3
* black==21.6b0
* certifi==2021.5.30
* charset-normalizer==2.0.3
* click==8.0.1
* colorama==0.4.4
* configparser==5.0.2
* crayons==0.4.0
* idna==3.2
* levenshtein==0.12.0
* mypy-extensions==0.4.3
* pathspec==0.9.0
* regex==2021.4.4
* requests==2.26.0
* selenium==3.141.0
* soupsieve==2.2.1
* toml==0.10.2
* urllib3==1.26.5
* webdriver-manager==3.4.2

<!-- GETTING STARTED -->
## Getting Started

To get this project running on your local machine, follow these simple steps:

### Installation

1. Clone the repo
   ```sh
   git clone https://github.com/ritwiktakkar/rdb-scraper.git
   ```
2. Make sure you're running Python 3 (I wrote and tested this project with Python 3.9.6 64-bit)
   ```sh
   python -V
   ```
3. Install all the packages specified in the configuration file (`requirements.txt`)
   ```sh
   pip install -r requirements.txt
   ```
4. You will need the [latest](https://www.google.com/intl/en_us/chrome/) version of Google Chrome installed on your machine
5. Execute `get_all_results.py` using Python
   ```sh
   PATH_TO_PYTHON_INTERPRETER PATH_TO_get_all_results.py
   ``` 



<!-- USAGE EXAMPLES -->
## Usage
<!-- Use this space to show useful examples of how a project can be used. Additional screenshots, code examples and demos work well in this space. You may also link to more resources. -->

**TO-DO**

<!-- CONTRIBUTING -->
## Contributing

Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request



<!-- LICENSE -->
## License

Distributed under the MIT License. See `LICENSE` for more information.



<!-- CONTACT -->
## Contact
üìß rt398 [at] cornell [dot] edu

üè† [ritwiktakkar.com](https://ritwiktakkar.com)

Project Link: [https://github.com/ritwiktakkar/rdb-scraper](https://github.com/ritwiktakkar/rdb-scraper)